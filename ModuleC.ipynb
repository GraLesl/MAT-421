{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOISthAmTfCD9j7tf+vRnqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GraLesl/MAT-421/blob/main/ModuleC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Root Finding\n",
        "\n",
        "Often times, it is critical to find the roots of a given function. For common and simple functions, a formula is occasionally availible which can be used to directly calculate the exact roots of a funciton. However, for more complicated functions, this is rarley the case and as such other methods must be employed.\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "Using the integrated fsolve function from scipy to solve for the root of $f(x) = cos(x) - x$ near $-2$."
      ],
      "metadata": {
        "id": "TdXK_ePAaKk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import optimize\n",
        "\n",
        "f = lambda x: np.cos(x) - x\n",
        "r = optimize.fsolve(f,-2)\n",
        "print(\"r =\", r)\n",
        "\n",
        "result = f(r)\n",
        "print(\"result =\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xv2TpnBaKUT",
        "outputId": "3c3e1a4d-21f4-4e7f-934a-a12571662f0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r = [0.73908513]\n",
            "result = [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One interesting idea is what would happen when a given function has no roots such as $f(x) = 1/x$. We will use the *full output* of fsolve to gain more insight."
      ],
      "metadata": {
        "id": "lhsOA7TqiVlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda x: 1/x\n",
        "\n",
        "r, infodict, ier, mesg = optimize.fsolve(f, -2, full_output=True)\n",
        "print(\"r =\", r)\n",
        "\n",
        "result = f(r)\n",
        "print(\"result =\", result)\n",
        "\n",
        "print(mesg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voXOuo-xiw5J",
        "outputId": "b1c4349f-99f5-476e-bca9-f24afe380f96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r = [-3.52047359e+83]\n",
            "result = [-2.84052692e-84]\n",
            "The number of calls to function has reached maxfev = 400.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the solution was not found due to the program reaching an error after not finding a proper root afer a given amount of iterations. One way this can be sidestepped is through the concept of tolerance.\n",
        "\n",
        "## Tolerance\n",
        "\n",
        "Tolerance is defined as the level of acceptable error for a given application. As such, we can consider values within tolerance to the true solution as correct when it comes to engineering applications.\n",
        "\n",
        "This idea can be applied in a few different ways to the root solving problem. One way seeks to find a solution which the $|f(x)|$ is a measure of the error, so the smaller the number the liklier we are to be at a root. Another approach, assuming the solver is iterative and the some value $x_i$ is the *i*th guess of an algorithm, then the change in guesses or $|x_{i+1} - x_i|$ is measured as the erorr. Both these processes have their pros and cons and can be used on an application by application basis."
      ],
      "metadata": {
        "id": "ZsWhgn-tjEse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bisection Method\n",
        "\n",
        "One aproach to an algorithmic root finding utilizes the intermediate value theorum. Assuming a continuous $f(x)$ where the $sign(f(a)) =/= sign(f(b))$, then there must be some point c where $a<c<b$ and $f(c) = 0$.\n"
      ],
      "metadata": {
        "id": "BcTwH1telgP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this concept, with a given initial guess at a and b where a and b are real scalars, $ a < b$ and $f(a) > 0 , f(b) < 0$, then a value $m = (b+a)/2$ is the midpoint between a and b. If $f(m)$ is within tolerance of zero, then m is a root. Otherwise, if $f(m) < 0$, m is an improvement on the lower bound and becomes the new b value. Vice versa when $f(m) > 0$. This process is programed below."
      ],
      "metadata": {
        "id": "0ewja8UPmdd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def my_bisection(f,a,b,tol):\n",
        "\n",
        "  if np.sign(f(a)) == np.sign(f(b)):\n",
        "    raise Exception(\"The scalars a and b do not bound a root\")\n",
        "\n",
        "  m = (a + b) / 2\n",
        "\n",
        "  if np.abs(f(m)) < tol:\n",
        "    return m\n",
        "  elif np.sign(f(a)) == np.sign(f(m)):\n",
        "    return my_bisection(f,m,b,tol)\n",
        "  elif np.sign(f(b)) == np.sign(f(m)):\n",
        "    return my_bisection(f,a,m,tol)\n",
        "\n",
        "\n",
        "f = lambda x: x**2 - 2\n",
        "\n",
        "r1 = my_bisection(f, 0,2,0.1)\n",
        "print(\"r1 =\", r1)\n",
        "r01 = my_bisection(f, 0,2,0.01)\n",
        "print(\"r01 =\", r01)\n",
        "\n",
        "print(\"f(r1) =\", f(r1))\n",
        "print(\"f(r01) =\", f(r01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXStmBu0nZQ1",
        "outputId": "b8e430f1-507c-4681-802a-11aceeea4245"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r1 = 1.4375\n",
            "r01 = 1.4140625\n",
            "f(r1) = 0.06640625\n",
            "f(r01) = -0.00042724609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newton-Rhapson Method\n",
        "\n",
        "Another option for root finding is the Newton-Rhapson method which takes $f(x)$ to be a smooth and continuous function, an initial guess $x_0$, and some unkonwn root $x_r$. Assuming $x_0 =/= x_r$, this approach makes successive iterations stepping closer and closer to the final root.\n",
        "\n",
        "Using the formula $x_i = x_{i-1} - \\frac{g(x_{i-1})}{g'(x_{i-1})}$. A next guess can be made which steps closer to the functions root. This process can be repeated until a final value is achieved.\n"
      ],
      "metadata": {
        "id": "lCClmTBDp9rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "import numpy as np\n",
        "\n",
        "def my_newton(f,df,x0,tol):\n",
        "\n",
        "  if abs(f(x0)) < tol:\n",
        "    return x0\n",
        "  else:\n",
        "    return my_newton(f,df,x0 - f(x0)/df(x0), tol)\n",
        "\n",
        "f = lambda x: x**2 - 2\n",
        "f_prime = lambda x: 2*X\n",
        "\n",
        "estimate = my_newton(f, f_prime, 1.5, 1e-6)\n",
        "print(\"estimate =\", estimate)\n",
        "print(\"sqrt(2) =\", np.sqrt(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcVAhPG2riQE",
        "outputId": "bfda1005-fd0f-42e8-9c68-17374a923f71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimate = 1.4142139123093318\n",
            "sqrt(2) = 1.4142135623730951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen, both the np.sqrt function and the function $f(x)$ approahc a very similar value when solving for the square root of 2.\n",
        "\n",
        "That being said, this solution can have its downfalls. Take for example the polynomial $ f(x) = x^3 - 100x^2 - x + 100$. This polynomial has roots at $x = 1$ and $x = 100$. If an initial guess is made at $x_0 = 0$ an interesting thing happens.\n",
        "\n",
        "Using the forumla from above the next step guess becomes $x1 = 0 - \\frac{100}{-1} = 100$. While this is a root of the initial function, it is much further from the initial guess of 0 which is very close to 1."
      ],
      "metadata": {
        "id": "yG4_Q_c-sNVp"
      }
    }
  ]
}